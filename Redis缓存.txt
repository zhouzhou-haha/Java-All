Redis(Remote Dictionary Server)：		
	Redis基于键值对(key-value)的NoSQL非关系型数据库(数据存于内存)，远程字典服务。基于内存存储，读写性能你高/适合存储热点数据(一瞬间大量请求访问的数据)

Redis默认端口：6379
Redis官网：https://redis.io		英文网站
	  https://www.redis.net.cn/	中文网站

实际开发业务:MySQL(存储大量普通数据) + Redis(少部分热点数据)

Redis重点：
	Java操作Redis
	Redis值数据类型
	缓存
	内存
	RDB/AOF
	集群
	
缓存：
	前端页面广告位数据无需每次查询后台系统的接口，可以在前台系统添加缓存，前台绝大部分请求的数据都是从Redis中获取，提高访问首页的速度(Nginx反向代理服务器)
	Redis的数据存放在内存当中，还可以将内存的数据利用快照和日志的形式保存到硬盘上，发生类似断电或机器故障的时内存数据不会丢失

主流缓存技术：
	Redis(单线程和I/O多路复用)/Memcached(多线程)

Redis发展背景：
	2008年，Redis作者Salvatore Sanfilippo在开发LLOOGG的网站时，需要实现一个高性能的队列功能，最开始使用MySQL实现，但是后来发现无论怎么优化SQL语句
	都不能使网站的性能提高上去，再加上自己囊中羞涩，决定做一个专属于LLOOGG的数据，这个就是Redis的前身。后来，Salvatore Sanfilippo将Redis 1.0的源码
	开放到GitHub上，可能他自己都没想到，Redis后来如此受欢迎

Redis特性：
	1.速度快
		Redis执行命令的速度非常快，读写性能可以达到10w/秒，纯内存访问
	2.基于键值对的数据结构服务器
	3.功能丰富(额外功能)
		键过期功能，实现缓存
		发布订阅功能，实现消息系统
		支持Lua脚本，利用脚本创造出新Redis命令	
		提供简单事务功能，一定程度上保证事务特性
		提供了流水线功能，客户端能将一批次命令一次性传到Redis
	4.简单稳定
	5.支持客户端语言多
		Redis提供简单的TCP通信协议，Redis客户端语言几乎涵盖主流变成语言，如Java/PHP/Py/C/C++
	6.持久化 
		将数据放在内存中是不安全的，一旦发生断电或者机器故障，重要数据丢失，RDB和AOF策略将内存的数据保存到硬盘中
	7.主从复制
		Redis提供复制功能，实现多个相同数据的Redis副本。
	8.高可用和分布式

Redis典型应用场景：
	1.缓存			加快数据访问速度，有效降低后端数据源压力
	2.排行榜系统		Redis提供列表和有序集合数据结构能构建各种排行榜系统
	3.计数器应用		Redis天然支持计数功能
	4.社交网络		社交网络访问量比较大，Redis提供的数据结构可以相对容易的保存一些特殊的数据
	5.消息队列系统		Redis提供发布订阅功能和阻塞队列功能

补充：
	Redis实例：指运行中的Redis服务器进程，一个独立的Redis数据库。
		每个Redis实例可以包含多个数据库，每个Redis实例都有自己的配置，数据存储环境和运行环境，可以独立运行并提供数据存储和服务
		每个数据库可以存储多个键值对数据。每个Redis实例都会监听一个端口，客户端可以通过端口与Redis通信
	
Redis客户端与服务端请求过程：

	客户端				服务端
			发送命令		执行命令
	client		 网络		Redis
			返回结果

	一条客户端命令生命周期：
		发送命令 --> 命令排队 --> 命令执行 --> 返回结果
		
单线程模型：	
		    队列		     	    Redis服务端
	命令1	命令2	.....	命令n		命令3

	补：所有命令都会进入一个队列中，然后逐个被执行，客户端命令执行顺序是不确定的，但不可能有两条命令同时执行

Redis安装：
Redis可执行文件说明：
	redis-server.exe		启动Redis服务
	redis-cli.exe			Redis命令行客户端	
	redis-sentinel			启动Redis Sentinel
	redis-benchmark			为Redis做基准性能测试
	redis-check-aof			Redis AOF持久化文件检测和修复工具
	redis-check-dump		Redis RDB持久化文件检测和修复工具

redis配置：
	修改Redis密码：	Redis配置文件(redis.windows.conf)中 Ctrl + F(搜索pass )注意：一定加空格	
			放开注释#requirepass foobared  ->  requeirepass + 密码  -> 重启Redis

	redis修改配置命令：		
		redis-cli config get dir		dir：Redis数据存储目录
		redis-cli config set dir
		

redis客户端命令行：								示例：
	redis-cli -h {host/127.0.0.1} -p 6379		连接Redis服务			redis-cli -h 10.10.1.116 -p 3379
	shutdown					停止Redis服务

	帮助文档命令：
		help @String..				查看帮助文档
		
Redis存储数据： key-value结构数据
Key数据结构类型：String			

Value数据结构类型：hash/String/Set/Sorted Set/list			记忆命令：数据结构类型首字母 + 命令
	哈希(字典)	hash
		哈希类型内部编码：
			ziplist		压缩列表
			hashtable	哈希表

	列表		list
		列表类型内部编码：
			ziplist		压缩列表		一种结构实现多种编码：Redis作者想通过不同编码实现效率和空间的平衡
			linkedlist	链表				

	集合		set				与下面数据结构详解一起看
		集合类型内部编码：				
			intset		整数集合
			hashtable	哈希表
			
	有序集合 		sorted set/zset
		有序集合内部编码：
			ziplist		压缩列表
			skiplist	跳跃表
		
	字符串		string(基础数据类型)	
		字符串类型内部编码：	
			int		8个字节的长整型
			embstr		小于等于39个字节的字符串
			raw		大于39个字节的字符串

	位图		Bitmaps
	HyperLogLog	基于概率的基数算法
	GEO		地理信息定位
	流		stream
	
String字符串类型(存储Token/普通键值对)：
	String类型Redis常用命令：	
	***	keys *				查看所有键    *代表任意字符   ?代表匹配一个字符   []代表匹配部分字符	
	***	exists key			检查键是否存在		返回值：1(存在)	0(不存在)
		select 数据库索引			切换数据库		返回值：地址:数据库索引号>
		flushdb				清除当前数据库
		flushall			清除所有数据库	
		del key	[key...]		删除一个或多个键		返回值：删除键的个数
	***	type key [key...]		返回指定键的值类型		返回值：对应值的类型
		rename key newkey		键重命名	
		randomkey			随机返回一个键		
		dbsize				返回当前数据库key的数量
		renamenx key newkey		只有newkey不存在时才会被覆盖	
		expire key seconds		设置生存时间，超过时间，自动删除键
		expireat key timestamp		在秒级时间戳timestamp后过期
		persist key seconds		清除生存时间
		TTL				返回键的剩余过期时间	返回值：{0(剩余过期时间)，-1(健没设置过期时间)，-2(键不存在)}	
		object encoding key		查看底层内部编码	
	***	set key value			赋值			key = hejia：name1：贺梅方	：表示层级，值可以设置为Json
		mset key value			批量设置值		
	***		setex key seconds value	  	设置键，设置秒级过期时间(短信验证码，自动过期)		setex code(键) 30(过期时间) 60(值)
	***		setnx key value		  	键必须不存在才能设置成功
	***	get key			  	取值
		mget key [key ...] 	  	批量获取值		mget 键1 键2
		incr key			自增操作，返回结果{错误(值不是整数)，自增结果(值是整数)，1(键不存在)}
		incrby key increment		自增指定数字
		decr key			自减操作
		decrby key increment		自减指定数字
		append key value		追加值
		strlen key			获取字符串长度
		getset key value		设置并返回原值
		rename oldkey newkey		针对key的重命名
		getrange key start end		获取键上的字符串的子字符串
		setrange key offset value  	设置指定位置的字符	

		String类型应用场景:
			1.缓存功能
			2.Redis作为视频播放数计数的基础组件(快速计数)/查询缓存
			3.共享Session，分布式将用户访问均衡到不同服务器上，用户刷新需要重新登录，Redis将Session集中管理
			4.限速

Hash哈希类型(存储对象POJO)：
	Redis hash是一个string类型的field和value的映射表
	
	Map<String,Map<String,String>>

	key			field			value
	键			字段			值

				username		zhangsan
	User			password		123456
				name			张三
	
	Hash类型Redis常用命令：
	***	hset key field value			设置值
	***	hget key field				获取值
	***	hdel key field [field ...]		删除一个或多个field
		hexists	key field			判断字符是否存在
	***	hsetnx key field value			当字段不存在时赋值
		hlen key				计算field个数
		hstrlen key field			计算value字符串长度
	***	hkeys key				只获取字段名
	***	hvals key				只获取字段值
		hgetall key				获取所有的field-value
		hmget key field	[field ...]		批量获取所有给定字段的值
		hmset key field value [field ...]	批量设置多个field-value对设置到哈希表key中
		hincrby key field increment		为哈希表key中的指定字段的整数值加上增量increment
		hincrbyfloat key field increment	为哈希表key中的指定字段的浮点数值加上增量increment

List列表类型：		有序元素可重复
	列表：key ->	a(key/value)  b(key/value)  c(key/value)  d(key/value)

	队列：
		特点：先进先出，异端进出
		lpush(入队)+rpop(出队) = Stack(队列)
	栈：
		特点：先进后出，同端进出
		lpush(入栈)+lpop(出栈) = Queue(栈)
	有限集合：
		lpush + ltrim = Capped Collection(有限集合)
	消息队列：
		lpush + brpop = Message Queue(消息队列)
			

	List类型Redis常用命令：	L(Left)		R(Right)
	***	lpush key value1 [value2]		添加元素，返回新元素之后list中元素的数量(从左侧插入)
		lpushx key value			为已存在的列表添加值(从左侧插入)
	***	rpush key value1 [value2]		添加元素，返回新元素之后list中元素的数量(从右侧插入)
		rpushx key value			为已存在的列表添加值(从右侧插入)
		linsert key before|after pivot value	向某个元素前后者后插入元素
	***	lpop key				移出并获取列表左侧的第一个元素(第一个元素)
	***	rpop key				移除并获取列表右侧的第一个元素(最后一个元素)
		lindex key index			通过索引获取列表中的元素
	***	llen key				获取列表长度
	***	lrange key start end			查找指定坐标范围内的元素列表，负数表示倒数
		lrem key count value			删除值为value的元素
			count > 0				从左到右，删除最多count个元素
			count < 0				从右到左，删除最多count绝对值个元素
			count = 0				删除所有个元素
		ltrim key start end			按照索引范围修剪列表
		lset key index value			通过索引设置列表元素的值
		blpop key1 [key2] timeout		移出并获取列表的第一个元素，如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止
		brpop key1 [key2] timeout		移出并获取列表的最后一个元素，如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止

		List类型应用场景:
			1.消息队列	
				lpush+brpop命令组合实现阻塞队列，生产者客户端用lrpush从列表左侧插入元素，
				多个消费者客户端使用brpop阻塞式抢尾部元素，保证消费负载均衡和高可用性
			2.文章列表
				每个用户都有自己的文章列表，分页展示文章列表，可以使用列表
	
Set集合类型：	string类型的无序集合
	set集合不允许有重复元素，集合中的元素是无序

	Set类型Redis常用命令：
	***	sadd key element [element ...]		向集合中添加一个或多个成员
	***	srem key element [element ...]		移除集合中一个或多个成员
	***	scard key				获取集合的成员数
		sismember key element			判断元素是否在集合中
	***	smembers key				返回集合中的所有成员
		srandmember key [count]			随机返回集合指定个数元素，元素不删除
		spop key				从集合中随机弹出元素，元素删除
		smove source destination element	将element元素从source集合移动destination集合
		集合交并补：
	***	sinter key1 [key2]			返回给定所有集合的交集
	***	sunion key1 [key2]			返回所有给定集合的并集
		sdiff  key1 [key2]			返回所有给定集合的补集/差集
		交并补结果保存：
		sinterstore destination key1 key2	将key1集合与key2交集的结果保存在destination集合中
		sunionstore destination key1 key2	将key1集合与key2并集的结果保存在destination集合中
		sdiffstore destionation key1 key2	将key1集合与key2差集的结果保存在destination集合中

		Set类型应用场景：
			sadd = Tagging(标签)
			spop/srandmember = Random item(生成随机数，比如抽奖)
			sadd + sinter = Social Graph(社交需求)

Sorted set有序集合类型：		应用：排行榜
	string类型元素的集合，不允许有重复的元素
	有序集合中元素关联一double类型的分数，通过分数为集合成员从小到大排序

	Sorted set类型Redis常用命令：
	***	zadd key score member [score member ...]		向有序集合添加一个或多个成员
		zcard key						获取有序集合的成员数
		zcount key min max					计算在有序集合中指定区间分数的成员数
		zlexcount key min max					计算有序集合中
		zscore key member					计算某个成员的分数
		zrank key member					计算某个成员的排名(由低到高)
		zrevrank key member					计算某个成员的排名(由高到低)
	***	zincrby key increment member				有序集合中对指定成员的分数加上增量
	***	zrem key member [member ...]				删除有序集合中一个或多个成员
	***	zrange key start end [withscores]			返回指定排名范围的成员(由低到高)
		zrevrange key start end [withscores]			返回指定排名范围的成员(由高到低)
		zrangebyscore key min max min [withscores]		按照分数从低到高返回
		zrevrangebyscore key max min [withscores]		按照分数从高到低返回
		zremrangebyrank key start end				删除指定排名内的元素
		zremrangebyscore key min max				删除指定分数范围的成员	
		集合操作交并补：
		zinterstore destination numkeys key [key ...]		计算给定的一个或多个有序集的交集，并存储在destination集合中
		zunionstore destination numkeys key [key ...]		计算给定的一个或多个有序集的并集，并存储在destination集合中
		补充：加上withscores会同时返回成员的分数	
		     zrevrange会按降序返回范围

		Sorted set类型应用场景：
			1.按照时间，视频播放量，获得的赞数做排行榜
			
	List/Set/Sorted set异同点：
				重复元素		是否有序		实现有序方式
		List		是		是		索引下标
		Set		否		否		无
		Sorted set	否		是		分数

	补充：Reids内部可以有多个数据库，数据上互相隔离
	迁移键：			把部分数据从一Redis迁移到另一Redis(从生产环境迁移到测试环境)
		move key db					将指定的键从源数据库迁移到目标数据库
		dump + restore：
			dump key				将键值序列化，格式采用RDB格式(源数据库)
			restore key ttl value			将序列化的值进行复原(目标数据库)	
			注意：开启两个客户端分步完成	
		migrate	host port key destination-db timeout	Redis实例间数据迁移，支持迁移多个键	
			host			目标Redis的IP地址
			port			目标Redis的端口
			key			需要迁移的键	
			destination-db		目标Redis的数据库索引
			timeout			迁移的超时时间(毫秒)
			migrate执行流程：
				源Redis执行migrate命令 -->  命令的数据传输在源Redis和目标Redis上完成 
					--> 目标Redis完成restroe发送OK给源Redis --> 根据migrate对应的选项是否删除源数据库上的键	

	遍历键：
		keys pattern/*			获取所有的键
		scan cursor [match pattern] [count number]	迭代遍历
		sscan key cursor [match pattern] [count count]	迭代集合中的元素
		zscan key cursor [match pattern] [count count]	迭代有序集合中的元素
			cursor			cursor是游标，每次scan遍历返回当前游标的值，第一次是0
			match pattern		可选参数，模式匹配
			count number		可选参数，表明要遍历的键个数，默认值是10

通用命令(key命令)：
	keys pattern				查找所有符合给定模式(pattern)的key
	exists key				检查给定key是否存在
	type key				返回key所存储值的类型
	del key					key存在，删除key

(Redis基础)
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
(Redis拓展)

Redis附加功能：
	慢查询分析	慢查询分析，找到有问题的命令进行优化
	Redis Shell	
	Pipeline	Pipeline(管道流水线)机制有效提高客户端性能
	事务与Lua	利用脚本创造出新的Redis命令
	Bitmaps		位图，操作位的字符串数据结构，节省内存
	HyperLogLog	基于概率的算法，节省空间
	发布订阅		基于发布订阅模式的消息通信机制
	GEO		提供了基于地理位置信息的功能

	慢查询：		
		例：MySQL提供慢查询日志帮助开发人员定位系统存在的性能问题
		慢查询日志：系统在命令执行前后计算每条命令的执行时间，当超过预设阀值，将命令的相关信息(命令执行时间)记录下来，并将命令标记为慢查询
		
		慢查询功能配置参数：	
			1.预设阀值：
				slowlog-log-slower-than = 10000微秒(默认值)
				注意：执行时间超过10000微秒，命令会被记录在慢查询日志中
				     slow-log-slower-than = 0		记录所有的命令
				     slowlog-log-slower-than < 0	不会记录任何命令

			2.慢查询记录存放：

				slowlog-max-len
				补充：Redis使用列表存储慢查询日志，slowlog-max-len是列表的最大长度，处于最大长度时，将最早插入的命令移除
			
			建议：
				1.需要根据Redis并发量调整阀值，1毫秒
				2.线上调大慢查询列表，1000以上
			     
		修改配置：
			1.修改配置文件
			2.命令动态修改
				config set slowlog-log-slower-than 20000
				config set slowlog-max-len 1000
				config rewrite				Redis配置持久化到本地配置文件

		慢查询日志访问和管理：
			slowlog get [n]			获取慢查询日志,n可以指定条数
			slowlog len			获取慢查询日志列表当前长度
			slowlog reset			清理慢查询日志

	Redis Shell：
		redis提供redis-cli/redis-server/redis-benchmark等Shell工具
		redis-cli(Pipeline机制)：
			redis-cli -help			查看redis-cli全部参数
				  -r 3 ping		-r代表命令执行多次，执行三次ping命令
				  -i 1 ping		-i代表每隔几秒执行一次命令，与-r连用
					例：redis-cli -r 5 -i 1 ping		每隔1s执行一次命令，一共执行5次		
				  -x set hello		代表从标准输入读取数据作为最后一个参数
				  -c			连接Redis Cluster节点使用，防止moved和ask异常
				  --scan/--partern	用于扫描指定模式的键，相当于scan
				  --slave		把当前客户端模拟成当前Redis节点的从节点，获取当前Redis节点的更细操作
				  --rdb			请求Redis实例生成并发送RDB持久化文件，保存在本地
				  --pipe		将命令封装成Redis通信协议定义的数据格式，批量发送给Redis执行
				  --bigkeys		使用scan命令对Redis的键进行采样，找到内存比较大的键值
				  --eval		用于执行指定Lua脚本
				  --latency		用于测试客户端到目标Redis的网络延迟
				  --latency-history	测试Redis网络延迟，以分时段的形式了解延迟信息
				  --latency-dist	以统计图的形式从控制台输出延迟统计信息
				  --stat		实时获取Redis的重要统计信息
				  --raw			返回格式化后的结果
			    	  --no-raw		返回结果是原始格式

		redis-server：
			redis-server			启动Redis
			redis-server --test-memory 1024	检测当前操作系统能否稳定分配指定的内存给Redis(调试和测试)

		redis-benchmark：
			redis-benchmark -c 50		-c代表客户端的并发数量(默认是50)
					-n 20000	代表客户端请求总量
						例：redis-benchmark -c 100 -n 20000		代表100个客户端同时请求Redis，一共执行20000次
					-q		显示redis-benchmark的requests per second信息
					-r 10000	向Redis中插入更多随机的键
					-p		每个请求pipeline的数据量
					-k		代表客户端是否使用keepalive(默认为1)
					-t 命令		对指定命令进行基准测试
					--cvs		将结果按照csv格式输出
						例：redis-benchmark -t get，set --csv

	Pipeline流水线机制(性能优化):			性能延迟 --> 网络
		没有Pipeline执行n次命令模型：
		客户端					服务端
				发送命令1
				返回结果1
				发送命令2		
				返回结果2			
		client		..网络..			Redis
		
				
				发送命令n
				返回结果n	

		使用Pipeline执行n条命令模型：
		客户端					服务端

							pipeline组成命令块
				发送pipeline命令		cmd5cmd4cmd3cmd2cmd1
							
							单线程执行

		client					Redis

							结果集
				返回pipeline结果		结果1结果2结果3结果4结果5

		Pipeline(流水线)机制将一组Redis命令进行组装，通过一次RTT传输给Redis，再将这组Redis命令的执行结果按顺序返回给客户端	
		Pipeline优势：
			Pipeline执行速度一般比逐条执行要快
			客户端和服务端的网络延迟越大，Pipe的效果越明显	

		pipeline与原生批量命令对比：
			原生批量命令原子，pipeline是非原子的
			原生批量命令是一个命令对应多个key，Pipeline支持多个命令
			原生批量命令是Redis服务端实现，Pipeline需要服务端和客户端的共同实现

		实际场景使用：
			将一次大量命令的Pipeline拆分成多次较小的Pipeline完成

	事务与Lua：
		事务：表示一组动作，要么全部执行，要么全部不执行
		
		事务四大特性(ACID):
			原子性	事务时不可分割的工作单位，事务包含的操作要么都做，要么都不做
			一致性	事务完成时，所有数据都保持一致
			隔离性	一个事务的执行不能被其他事务干扰
			持久性	一个事务一旦提交，它对数据库中的数据的改变时永久性的	

		Redis事务命令：	将一组需要一起执行的命令放到multi和exec命令之间执行
			watch key	在使用事务之前，确保事务中的key没有被其它客户端修改过，才执行事务
			unwatch
			multi		事务开始		
			exec		事务结束
			discard		停止事务				补充：Redis不支持回滚功能
				
			乐观锁：每次拿数据的时候都认为别人不会修改数据。更新数据时判断有没有更新数据	

				1 客户端使用watch监视一个或多个键
				2 在multi块内执行一系列命令，事务开始
				3  客户端执行exec，Redis检查被监视的键是否被其他客户端修改，发现，事务失败返回空回复
				4 根据事务执行结果，客户端选择重试事务操作或执行其他逻辑
				
				使用场景：读多写少，处理高并发
			
			悲观锁：每次拿数据都认为数据会被修改，每次拿数据都会上锁

		Redis与Lua：
		Redis中执行Lua脚本：
			eval 内容脚本  key个数  key列表  列表参数	执行脚本内容
			evalsha 脚本SHA1值 key个数 key列表 参数列表	执行脚本
			redis-cli --eval			执行Lua脚本文件，事先在客户端编写好Lua脚本	
			redis-cli script load			将脚本内容加载到Redis内存中，得到SHA1
			
		Redis管理Lua脚本：
			script load script(脚本)		将Lua脚本加载到Redis内存中，返回给定脚本的SHA1校验和
			script exists sha1		判断sha1是否已经加载到Redis内存中
			script flush			清除Redis内存中已经加载的所有Lua脚本
			script kill			杀掉正在执行的Lua脚本，没有执行过任何写操作
			shutdown [no]save		停止整个Redis进程来停止脚本的运行

		Lua脚本使用场景和优势：
			Lua脚本在Redis中是原子执行的，执行过程中不会插入其它命令
			帮助开发和运维创造出自己定制的命令，并将命令常驻在Redis内存中，实现复用
			Lua脚本可以将多条命令一次性打包，有效减少网络开销

	Bitmaps(位图)：
		目的：Redis提供Bitmaps"数据结构"实现对位的操作

		概念：Bitmaps是字符串，可以对字符串的位进行操作Bitmaps单独提供一套命令。
			可以将Bitmaps想象成一以位为单位的数组，数组的每个单元只能存储0和1，数组的下标在Bitmaps中为偏移量
			
		Bitmaps命令：		Bitmaps
			setbit key offset value			设置键的第offset位的值
			getbit key offset			获取键的第offset位的值
			bitcount key [start] [end]		获取Bitmaps指定范围值为1的个数
			bitop operation destkey key [key ...]	对一个或多个二进制位的字符串做操作并将结果保存在destkey中
		      		operation --> and(交集) or(并集) not(非) xor(异或)
			bitpos key targetBit [satrt] [end]	返回Bitmaps中第一个值为targetBit的偏移量，通过start和end指定查询范围
		
		Bitmap适用场景:
			1.低基数情况(low cardinality),列值的种类低于128种
			2.不频繁更新的表/只读表
			3.统计列值有多少种

	HyperLogLog(基数算法)：
		定义：HyperLogLog是Redis的高级数据结构，是用来做基数统计的算法
		
		基数：就是每一位的数码可以有多少个数字来表示，十进制，基数是十
		     比如数据集{1，3，5，7，5，7，8}，这个数据集的基数集为{1，3，5，7，8}，基数是5

		HyperLogLog命令：
		pfadd key element [element ...]			向HyperLogLog添加元素，添加成功返回1
		pfcount key [key ...]				返回给定HyperLogLog的基数估算值，存在一定误差
		pfmerge destkey sourcekey [sourcekey ...]	将多个HyperLogLog合并为一个
			
		HyperLogLog优点：
			在输入元素的数量或者体积非常大时，计算基数所需的空间是固定的，并且很小
			只计算总数，不需要获取单条数据

	发布订阅(Pub/Sub)机制：			类似nacos
		Redis提供基于"发布/订阅"模式的消息机制，消息发布者和订阅者不进行直接通信，发布者客户端向指定的频道发布消息，订阅该频道的每个客户端都可以收到消息
				Redis发布订阅模型
							  Redis
		发布者	   --------发布publish-------->	   频道1(channel1)	频道2
		
							   订阅subscribe/不订阅unsubscribe
				
					   订阅者	  订阅者		 订阅者	

		命令：
			publish chanel message			为频道发布消息，返回订阅者个数
			subscribe channel [channel ...]		当前客户端订阅一个或多个频道
			订阅之后：
			unsubscribe [channel1 [channel ...]]	取消对指定频道的订阅
			psubscribe pattern [pattern ...]	按照模式订阅
				例：psubscribe it*			订阅以it开头的所有频道
			punsubscribe [pattern [pattern ...]]	按照模式取消订阅
				例：punsubscribe it*			取消订阅以it开头的所有频道
			pubsub channels [pattern]		查看活跃的频道，活跃的频道指最少有一个订阅者
			pubsub numsub [channel ...]		查看频道订阅数
			pubsub numpat				查看通过模式的订阅数

		使用场景：
			聊天室/公告牌/服务之间利用消息解耦

	GEO(地理信息定位)：
		支持存储地理位置信息用来存储实现附近位置，摇一摇这类依赖于地理位置信息的功能
		geoadd key longitude latitude member 			增加地理位置信息,返回添加成功的个数
			[longitude]		经度	
			[latitude]		纬度
			[member]		成员
			[key]			地理位置信息的集合
				例：geoadd cities:location 116.28 39.55 beijing
		gepos key member [member ...]				获取成员的地理位置的经纬度
		geodist key member1 member2 [unit]			获取两个地理位置的距离
			unit		代表返回结果的单位
				m		米
				km		公里
				mi		英里
				ft		尺	
		georadius key longitude latitude radiusm|km|kf|mi 	以一个地理位置为中心算出指定半径内的其它地理信息位置
		georadiusbymember key member radiusm|km|ft|mi
			[withcoord]		返回结果中包含经纬度
			[withdist]		返回结果中包含离中心节点位置的距离
			[withhash]		返回结果中包含geohash
			[COUNT count]		返回结果的数量
			[asc|desc]		返回按照离中心节点的距离做升序或降序
			[stroe key]		将返回结果的地理位置信息保存到指定键
			[storedist key]		将返回结果距离中心节点的距离保存到指定键
		geohash key member [member ...]	Redis将二维经纬度转换为一个字符串，返回member的geohash值
		zrem key member						删除地理位置信息	

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
客户端(常用)：
	Redis指定RESP(Redis Serialzation Protocol/Redis序列化协议)实现客户端与服务端的交互，客户端将命令封装格式，服务端解析回复
	RESP客户端发送命令格式：			例：set hello world
		*参数数量 CRLF			*3 \r\n
		$参数1的字节数量 CRLF		$3 \r\n
		参数1 CRLF			set \r\n	--->实际输出格式(序列化)：
		...				$5 \r\n		--->	*3\r\n$3\r\nset\r\n$5\r\nhello\r\n$5\r\nworld\r\n
		$参数N的字节数量 CRLF		hello \r\n
		参数N CRLF			$5 \r\n
						world \r\n
	Redis解析回复结果格式：
		状态回复：	+[OK]		补充：实际看到结果的格式就是OK，没有＋
		错误回复:		-[error]
		
		Redis查询真正结果格式：
			nc 127.0.0.1 6379
			telnet 127.0.0.1 6379	

	Java客户端Jedis和RESP.app：
	RESP.app/Jedis：
		RESP.app是用于Redis命令行交互式的可视化工具，支持直接输入和执行Redis命令，查看命令响应结果
		Jedis属于Java的第三方开发包，用于Java应用程序与Redis进行交互，提供丰富的API方法
			通过Jedis，Java开发者可以轻松连接到Redis服务器，进行数据的CRUD操作

	Java客户端：Jedis/RedisTemplate/AllcoreRedis(底层封装RedisTemplate)
	
	Jedis(了解，RedisTemplate为主流)：		
	Jedis使用：
		1.引入依赖：
			<dependency>
				<groupId>redis.clients</groupId>
				<artifactId>jedis</artifactId>
				<version>2.8.2</version>		版本老旧，容易导致客户端跟不上服务端的速度，bug不能及时更新
			</dependency>
		
		2.Jedis基本使用：			网络操作可以用异常捕获
			Jedis jedis = null；
			try{
				jedis = new Jedis("127.0.0.1",6379);		Jedis初始化/Redis直接连接
				jedis.set("hello","world");			赋值jedis.set(),直接调用Redis常用命令，将Java对象序列化为二进制
				String value = jedis.get("hello");		取值，反序列化为Java对象，反序列化工具XML，Json，protostuff
			}catch(Exception e){							具体序列化操作见pdf141
				log.error(e.getMessage(),e);
			}finally{
				if(jedis != null){
					jedis.close();
				}
			}
			
			初始化Jedis常用构造函数：
				Jedis(final int host,final int port)
				Jedis(final String host,final int port,final int connectionTimeout,final int soTimeout)
					host			Redis主机地址
					port			端口号
					connectionTimeout	客户端连接超时
					soTimeout		客户端读写超时

	Jedis连接池：
		Jedis直连：

		1.Jedis jedis = new Jedis()  ----2.get|set|ping命令--->	Redis	
		4.jedis.close()		     <---3.return result------

				Jedis直接连接Redis(不高效)
		使用场景：适用少量长期连接的场景

		Jedis连接池：
		生产环境中使用连接池的方式对Jedis连接进行管理
			
			1.borrow			2.get|set|ping
		Jedis		   getJedisFromPool
			4.return			3.Result
			1.borrow			2.get|set|ping
		Jedis		   getJedisFromPool			Redis
			4.return			3.Result
			1.borrow			2.get|set|ping
		Jedis		   getJedisFromPool
			4.return			3.Result
	      JedisPool
				Jedis连接池使用方式
		连接池预先初始化Jedis连接，每次从Jedis连接池借用，用完归还给池子
			Jedis提供JedisPool类和common-pool通用对象池工具对Jedis连接池的管理工具
		
		Jedis连接池的使用：
			GenericObjectPoolConfig poolconfig = new GenericObjectPoolConfig();		common-pool连接池默认配置
			JedisPool jedisPool = new JedisPool(poolConfig,"127.0.0.1",6379);		初始化Jedis连接
			Jedis jedis = null；
			try{
				jedis = jedisPool.getResource();					从连接池获取对象
				jedis.get("hello");
			}catch(Exception e){
				logger.error(e.getMessage(),e);
			}fianlly{
				if(jedis != null){
					jedis.close();
				}
			}

			common-pool配置：
			poolConfig.setMaxTotal(GenericObjectPoolConfig.DEFAULT_MAX_TOTAL * 5);		//设置最大连接数是默认值的5倍
			poolConfig.setMaxIdle(GenericObjectPoolConfig.DEFAULT_MAX_IDLE * 3)		//设置最大空闲连接数是默认值的3倍
			poolConfig.setMinIdle(GenericObjectPoolConfig.DEFAULT_MIN_IDLE * 2)		//设置最小空闲连接数是默认值的2倍
			poolConfig.setJmxEnabled(true);							//设置开启jmx功能
			poolConfig.setMaxWaitMillis(3000);						//设置连接池没有连接后客户端最大等待时间

	Redis中使用Pipeline实现批量删除：			
		public void mdel(List<String> keys){
			Jedis jedis = null;
			try{
				jedis = new Jedis("127.0.0.1",6379);
				Pipeline pipeline = jedis.pipelined();
				for(String key:keys){
					pipeline.del(key);
				}	
				pipeline.sync();
				piepline.syncAndReturnAll()	
			}catch(Exception e){
				logger.error(e.getMessage(),e);
			}finally{
				if(jedis != null){
					jedis.close();
				}
			}
				
		}
		
		pipeline.sync()			执行命令
		pipeline.syncAndReturnAll()	将pipeline命令结果返回
		
	Jedis中Lua脚本：(略ppt146页)	

	Spring Data Redis -> RedisTemplate
	RedisTemplate(主流技术)：**************************************************************************************************************************************************
		Spring框架提供Spring-data-redis，提供spring应用中通过简单配置访问redis服务，对redis底层开发包进行高度封装
			功能：	提供不同Redis客户端整合(Jedis和Lettuce)
				提供RedisTemplate统一API操作Redis
				支持Redis的发布订阅模型
				支持Redis哨兵和Redis集群
				支持基于Lettuce的响应式编程
				支持基于JDK，JSON,字符串，Spring对象的数据序列化和反序列化
				支持基于Redis的JDKCollection实现
			
		RedisTemplate类：
			1.连接池自动管理
			2.针对jedis客户端中大量api进行归类封装，将不同数据类型的操作API封装到不同类型中
				    redisTemplateAPI			  返回值类型			     说明
				redisTemplate.opsForValue()		ValueOperations			操作string类型数据
				redisTemplate.opsForHash()		HashOperations			操作hash类型数据			
				redisTemplate.opsForList()		ListOperations			操作list类型数据				
				redisTemplate.opsForSet()		SetOperations			操作set类型数据
				redisTemplate.opsForZSet()		ZSetOperations			操作SortedSet类型数据				

			3.将事务操作封装，有容器控制
			4.针对数据的序列化/反序列化，提供多种可选择策略(RedisSerializer)

			setKeySerializer()/setValueSerializer()设置键值序列化方式
				序列化策略：
				JdkSerializationRedisSerializer	(POJO对象序列化字节数组)
			常用	StringRedisSerializer		(key/value为字符串的场景序列化)	手动完成序列化和反序列化
				JacksonJsonRedisSerializer	(POJO对象序列化为json格式)

				自定义序列化方式：
					1 实现RedisSerializer
					2 接口实现 serialize()和deserialize()方法
					3 通过RedisTemplate的setKeySerializer()和setValueSerializer()方法设置自定义序列化方式
		
		RedisTemplate中API使用：
			1.引入依赖：
			<dependency>
				<groupId>org.springframework.boot</groupId>
				<artifactId>spring-boot-satrter-data-redis</artifactId>
			</dependency>
			<dependency>
				<groupId>org.apache.commons</groupId>
				<artifactId>commons-pool2</artifactId>
			</dependency>
			<dependency>
				<groupId>com.alibaba</groupId>
				<artifactId>fastjson</artifactId>
				<version>1.2.68</version>
			</dependency>

			2.application.yml配置Redis数据源：
			***	spring.redis.port = 6379			Redis服务器连接端口
			***	spring.redis.host = 127.0.0.1			Redis服务器地址
			***	spring.redis.database = 0			Redis数据库索引		
			***	spring.redis.password = 			Redis服务器连接密码
				spring.redis.jedis.pool.max-active = 8		连接池最大连接数
				spring.redis.jedis.pool.max-wait = -1ms		连接池最大阻塞时间(负数不限制)
				spring.redis.jedis.pool.max-idle = 8		连接池中最大空闲连接		
				spring.redis.jedis.pool.min-idle = 0		连接池中最小空闲连接
				spring.redis.timeout = 5000ms			连接超时时间

			3.编写Redis配置类RedisConfiguration，为key/value配置序列化方式	
				1.创建配置类，注入Bean
				2.创建RedisTemplate对象			
				3.创建连接工厂				
				4.创建JSON序列化工具
				5.设置key的序列化				key序列化(配置的序列化器使key正常展示)，不设置序列化器(乱码展示)
				6.设置Value的序列化
				7.返回
				@Configuration
				public class RedisConfiguration{
					@Bean
					public RedisTemplate redisTemplate(RedisConnectionFactory redisConnectionFactory){
						RedisTemplate redisTemplate = new RedisTemplate();
						redistemplate.setConnectionFactory(redisConnectionFactory);
						redisTemplate.setKeySerializer(new StringRedisSerializer());		补充：设置序列化器，key/value才能正常展示，否则乱码		
						return redisTemplate;
					}	
				}
			
			4.调用Bean对象RedisTemplate
				@Autowired
				private RedisTemplate redisTemplate；
					
				ValueOperations valueOperations = redisTemplate.opsForValue();			操作String类型数据
				HashOperations hashOperations = redisTemplate.opsForHash();			操作Hash类型数据	
				ListOperations listOperations = redisTemplate.opsForList()			操作list类型数据				
				SetOperations setOperations = redisTemplate.opsForSet()				操作set类型数据
				ZSetOperations zSetOperations = redisTemplate.opsForZSet()			操作SortedSet类型数据	

				valueOperations.set("name","北京")				string类型调用对应方法操作数据
				valueOperations.get(key);					从Redis内存中获取值
				......
					补充：value塞什么类型，取值就用什么类型				

			
	客户端管理命令:			Redis提供客户端相关API对客户端状态进行监控和管理
		客户端API：	
			client list			列出与Redis服务端相连的所有客户端连接信息↓
				id，addr，fd，name		客户端标识
					id				客户端连接唯一标识
					addr				客户端连接的ip和端口
					fd				fd=-1表示当前客户端是外部客户端
					name				客户端的名字
				qbuf，qbuf-free			输入缓冲区，为客户端发送命令到Redis执行命令提供缓冲
					qbuf				缓冲区总容量
					qbuf-free			缓冲区剩余容量
				obl，oll，omem			输出缓冲区，为Redis和客户端交互返回结果提供缓冲
					obl				固定缓冲区的长度
					oll				动态缓冲区列表的长度
					omem				使用的字节数
				age，idle			客户端存活状态
					age				当前客户端已经连接的时间
					idle				最近一次的空闲时间		age = idle(连接一直处于空闲状态)
				flag				客户端类型标识
					flag = S			当前客户端是slave客户端	
					flag = N			当前客户端是普通客户端
					flag = O			当前客户端正在执行monitor命令
				db				当前客户端正在使用的数据库索引下标
				sub/psub			当前客户端订阅的频道或者模式数
				multi				当前事务中已执行命令个数
				cmd				客户端最后一次执行的命令
			client setName xx		给客户端设置名字
			client getName			查看当前客户端的名字
			client kill ip:port		杀掉指定IP和端口的客户端(比如设置timeout=0时产生的长时间idle客户端)
			client pause timeout(毫米)	客户端连接会被阻塞timeout毫秒数，对普通和发布订阅客户端有效
			monitor				监听Redis正在执行的命令,大并发可能存在输出缓冲区暴涨

	客户端相关配置：
		config set maxclients 10000		设置最大客户端连接数(默认值10000)
		config get maxclients 			获取最大客户端连接数
		config set timeout 30			设置连接的最大空闲时间(默认值0，实际开发设置 > 0)
		config set tcp-keepalive 0		检测TCP连接活性的周期(默认值0，不检测)，建议60[只在linux生效]
		config set tcp-backlog			设置服务器端等待被接收的连接队列的大小
			补充：服务器端正在处理连接请求时，如果有新的请求到达，服务尚未来得及处理，新请求就会进入backlog队列中等待被处理

		info clients				客户端统计片段
			connected_clients			当前Redis节点的客户端连接数	
			client_longest_output_list		当前所有输出缓冲区队列对象个数最大值	
			client_biggest_input_buf		当前所有输入缓冲区中占用最大容量
			blocked_clients				正在执行阻塞命令	
		info stats				客户端统计片段
			total_connections_received		Redis自启动以来处理客户端连接总数	
			rejected_connections:0			Redis自启动以来拒绝的客户端连接数，重点监控

	客户端常见异常：
		1.redis.clients.jedis.exceptions.JedisConnectionException：Could not get a resource from the pool	
			无法从连接池获取连接
				直接原因：
					1.默认配置，池中对象都被占用，从JedisPool中借不到Jedis，等待超时，抛出异常
					2.设置blockWhenExhausted=false，JedisPool中没有资源，抛出异常

				根本原因：
					1.高并发连接池设置过小，供不应求，设置比默认最大连接数(8个)多一些即可
					2.未正确使用连接池，没有进行释放
					3.存在慢查询操作，慢查询持有的Jedis对象归还速度慢，造成连接池拥堵
					4.Reids服务端由于一些原因造成客户端执行过程阻塞
					
		2.redis.clients.jedis.exceptions.JedisConnectionException:java.net.SocketTimeoutException:Read timed out
			客户端读写超时
				原因：
					1.读写超时时间设置过短
					2.客户端与服务端网络不正常
					3.Redis自身发生阻塞
					4.命令自身比较慢

		3.redis.clients.jedis.exceptions.JedisConnectionException:java.net.SocketTimeoutException:connect timed out
			客户端连接超时：
				原因：
					1.连接超时时间设置过短
					2.Redis发生阻塞，导致tcp-baklog已满，造成新的连接失败
					3.客户端与服务端网络不正常

		4.redis.clients.jedis.exceptions.JedisConnectionException:Unexpected end of stream
			客户端缓冲区异常：
				原因：
					1.输出缓冲区满
					2.长时间闲置连接被服务端主动断开
					3.不正常并发读写：Jedis对象同时被多个线程并发操作
		
		5.redis.clients.jedis.exceptions.JedisDataException:BUSY Redis is busy running a script.
			You can only call SCRIPT KILL or SHUTDOWN NOSAVE.
			原因：Redis正在执行Lua脚本，并且超过lua-time-limit，Jedis调用Redis抛出异常
					
		6.redis.clients.jedis.exceptions.JedisDataException:LOADING Redis is loading the dataset in memory
			原因：Jedis调用Redis时，Redis正在加载持久化文件，抛出异常

		7.redis.clients.jedis.exceptions.JedisDataException:OOM command not allowed when used memory > 'maxmemory'
			原因：Jedis执行写操作时，如果Redis的使用内存大于maxmemory设置，抛出异常
			
		8.redis.clients.jedis.exceptions.JedisDataException:ERR max number of clients reached
			原因：客户端连接数超过maxclients，新申请连接抛出异常

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
持久化(RDB/AOF)：		
	Redis支持RDB和AOF两种持久化机制，持久化有效避免因进程退出造成的数据丢失问题，下次重启使用持久化的文件可实现数据恢复

	更改数据目录位置：dir 
	
	RDB：设置固定的时间间隔，将当前进程数据生成快照保存到硬盘的过程
	触发RDB持久化过程：
		手动触发
		自动触发
		
		手动触发：
			save(已废弃)	阻塞当前Redis服务器，直到RDB过程完成为止。对于内存数据量大的实例造成长时间阻塞，线上不建议使用
			bgsave		Redis进程执行fork操作创建子进程，RDB持久化过程由子进程完成，完成后自动结束。阻塞发生在fork阶段，时间短

		自动触发：
			1.save相关配置，例save m n ，表示m秒内数据集存在n次修改时，自动触发bgsave
			2.执行debug reload命令重新加载Redis时，自动触发save操作
			3.默认情况下执行shutdown命令，没有开启AOF持久化，自动执行bgsave
			4.从节点执行全量复制操作，主节点自动执行bgsave生成RDB文件并发送给从节点
			
						bgsave
					   	   ↓
		  	 有其它子进程执行，直接返回←父进程←返回信号通知
					   	  ↓	  ↑
					  	 fork → 子进程
					   	  ↓	  ↓
						响应命令 生成RDB文件

				     	     bgsave执行流程
	
			RDB文件保存：
				config set dir {newDir}				修改文件路径到可用文件路径
				config set dbfilename {newFileName}		修改文件名

			RDB文件压缩(默认开启)：	
				config set rdbcompression {yes|no}		压缩RDB文件，默认开启
			
			RDB文件校验：
				redis-check-dump				Redis加载损坏的RDB文件拒绝启动，检测RDB文件获取错误报告

		RDB优缺点：
			优点：
				RDB是紧凑压缩的二进制文件，代表Redis在某个时间点上的数据快照，使用用于备份，全景复制
				Redis加载RDB恢复数据远快于AOF
			缺点：
				RDB方式无法做到实时持久化，besave每次都要执行fork操作创建子进程，频繁执行成本过高
				老版本Redis无法兼容新版RDB格式
	
	AOF(主流方式)：以独立日志的方式记录每次写命令，使用File文件保存AB时间点之间用户执行的所有语句。重启时再重新执行AOF文件中的命令达到数据恢复
					命令写入			
					   ↓			所有写入命令追加到aof_buf(缓冲区)中
					AOF缓冲
					      ↓			AOF缓冲区根据对应的操作向硬盘做同步操作
					AOF文件 <--> rewrite	AOF文件越来越大，定期对AOF文件进行重写，达到压缩
					   ↑
					   重启			Redis服务器重启时，可以加载AOF文件进行数据恢复
					
				       AOF工作流程

			AOF采用文本协议格式原因：
				文本协议具有很好的兼容性
				开启AOF后，所有的命令都包含追加操作，采用协议格式，避免二次开销
				文本协议具有可读性，方便修改和处理

			AOF将命令追加到缓冲区原因:
				1.Redis提供多种缓冲区同步硬盘的策略，在性能和安全性方面做出平衡
				2.AOF文件直接追加到硬盘，性能取决于当前硬盘负载

		AOF缓冲区同步文件策略：
			appendfsync = 
				always		命令写入aof_buf后调用系统fsync操作同步到AOF文件，fsync完成后线程返回
				everysec	命令写入aof_buf后调用系统write操作，write完成后线程返回
				no		命令写入aof_buf后调用系统write操作，不对AOF文件做fsync同步，同步硬盘操作由操作系统负责
			
			补充：
				always，每次写入都要同步AOF文件，在一般的SATA硬盘上，只能支持大约几百TPS写入，不建议使用
				no，操作系统每次同步AOF文件的周期不可控，会加大每次同步硬盘的数据量，数据安全性不能保证	
				everysec(默认配置)，能做到兼顾性能和数据安全性
				fsync强制将数据从系统缓存写入磁盘操作，确保数据持久化

		重写机制：
			目的：命令不断写入AOF文件，文件越来越大，为解决该问题，Redis引入AOF重写机制，更小的AOF文件可以更快的被Redis加载
			重写：文件重写将Redis进程内的数据转化为写命令同步到新AOF文件的过程

			触发AOF重写过程：
				手动触发：
					直接调用bgrewriteaof命令

				自动触发：
					auto-aof-rewrite-min-size：表示运行AOF重写文件最小体积
					auto-aof-rewrite-percentage：表示当前AOF文件空间和上一次重写后AOF文件空间的比值

					    bgrewriteaof
					   	  ↓					
		  	 			父进程 ← 返回信号通知		
					   	  ↓	    ↑				
				   aof_buf ←←← fork     子进程
				      ↓   	  ↓	    ↓
				      ↓	aof_rewrite_buf	→ 新AOF文件
				      ↓			    ↓
				   旧AOF文件 ←←←←←←←←←←

				     	     AOF重写运作流程
		
			重写后AOF文件变小原因：
				进程内超时的数据不再写入
				旧的AOF文件含有无效命令
				多条写命令可以合并为一个

		重启加载：实际使用时，两种持久化策略会同时使用，使用RDB在较长的时间间隔上做持久化，使用AOF补齐时间间隔内出现数据丢失现象
			
			Redis持久化文件加载流程：
				1.AOF持久化开启且存在AOF文件时，优先加载AOF文件
				2.AOF关闭或者AOF文件不存在时，加载RDB文件
				3.加载AOF/RDB文件成功后，Redis启动成功
				4.AOF/RDB文件存在错误，Redis启动失败，并打印错误信息

		文件校验：	
			加载损坏的AOF文件会拒绝启动，打印错误日志
			redis-check-aof --fix		修复AOF文件
			diff -u				数据对比，找出丢失数据，人工补全

	持久化阻塞主线程：
		Redis持久化功能影响Redis性能
		1.fork操作创建子进程耗时/fork阻塞	
			高流量的Redis实例OPS在5w以上，fork操作在秒级将拖慢Redis几万条命令执行，线上应用延迟影响非常明显

			优化：
				使用物理机或者高效支持fork操作的虚拟化技术
				控制Redis实例最大可用内存，线上每个Redis实例内存控制在10GB以内
				合理配置Linux内存分配策略，避免物理内存不足导致fork失败
				降低fork操作的频率，适度放宽AOF自动触发时机

		2.子进程开销监控
			子进程负责AOF或者RDB文件的重写，主要涉及CPU,内存，硬盘，CPU，内存，硬盘开销严重
				Linux有写时复制机制，父子共享相同的内存物理页，避免内存消耗翻倍
	
			优化：
				不要和其它CPU密集型服务部署在一起
				尽量保证在同一时刻只有一个子进程在执行重写工作
				避免大量写入时做子进程重写操作
				不要和其它高硬盘负载的服务部署在一起
				AOF重写时会消耗大量硬盘IO，可以开启配置no-appendfsync-on-rewrite，默认关闭
				开启AOF功能的Redis用于高流量写入场景，Redis实例的瓶颈主要在AOF同步硬盘上
				单机配置多个Redis实例的情况，可以配置不同实例分盘存储AOF文件

		3.AOF追加阻塞耗时/AOF刷盘阻塞	
			Redis使用另一条线程每秒执行fsync同步硬盘，硬盘资源紧张导致AOF追加阻塞
			
			AOF刷盘阻塞定位：
				info persistence 查看aof_delayed_fsync指标，每次发生fdatasync阻塞主线程时累加
			
	多实例部署：
		Redis单线程架构无法充分利用CPU多核特性，通常的做法是在一台机器上部署多个Redis实例
		单机部署多个Redis实例，防止出现多个子进程执行重写操作，导致CPU和IO资源竞争，子进程隔离控制

		info Persistence	提供监控子进程运行状况的度量指标

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
阻塞：
	Redis单线程架构，所有读写操作都是一条主线程中完成，Redis用于高并发场景时，如果出现阻塞，导致系统变慢，影响用户体验
	
	阻塞内在原因：不合理使用API/数据结构，CPU饱和，持久化阻塞
	阻塞外在原因：CPU竞争，内存交换，网络问题

	阻塞原因：
	内在原因：
		API或数据结构使用不合理：
			阻塞原因：
				慢查询只记录命令执行时间，发生阻塞异常，可能不是当前命令缓慢，而是等待其它命令执行，数据量较大且命令算法复杂度是O(n)
			排查：
				发现慢查询：slowlog get {n}	获取最近n条慢查询命令	
				发现大对象：redis-cli -h {ip} -p {port} --bigkeys	 	
			解决：
				调整命令位低算法度命令
				调整大对象，将大对象拆分为多个小对象，防止一次命令操作过多数据

		CPU饱和：
			阻塞原因：
				单线程Redis处理命令只能使用一个CPU。CPU饱和指Redis将单核CPU使用率跑到100%，导致Redis无法处理更多命令
			排查：
				查看CPU使用率：执行top命令
				查询Redis并发量：redis-cli -h {ip} -p {port} --stat		
			解决：
				集群化水平扩展分摊OPS压力
					补充：OPS指每秒操作数，Redis服务器处理命令或操作的效率和速度，OPS越高，Redis在单位时间内能处理更多的操作，有更高的性能
				检查是否有过度优化的内存

		持久化阻塞：
			阻塞原因：
				fork阻塞
					高流量的Redis实例OPS在5w以上，fork操作在秒级将拖慢Redis几万条命令执行，线上应用延迟影响非常明显

			优化：
				使用物理机或者高效支持fork操作的虚拟化技术
				控制Redis实例最大可用内存，线上每个Redis实例内存控制在10GB以内
				合理配置Linux内存分配策略，避免物理内存不足导致fork失败
				降低fork操作的频率，适度放宽AOF自动触发时机
	
			阻塞原因：
				子进程开销监控
					子进程负责AOF或者RDB文件的重写，主要涉及CPU,内存，硬盘，CPU，内存，硬盘开销严重
						Linux有写时复制机制，父子共享相同的内存物理页，避免内存消耗翻倍

			优化：
				不要和其它CPU密集型服务部署在一起
				尽量保证在同一时刻只有一个子进程在执行重写工作
				避免大量写入时做子进程重写操作
				不要和其它高硬盘负载的服务部署在一起
				AOF重写时会消耗大量硬盘IO，可以开启配置no-appendfsync-on-rewrite，默认关闭
				开启AOF功能的Redis用于高流量写入场景，Redis实例的瓶颈主要在AOF同步硬盘上
				单机配置多个Redis实例的情况，可以配置不同实例分盘存储AOF文件

			阻塞原因：
				AOF刷盘阻塞	
					硬盘资源紧张，fsync操作需要等待，直到写入完成

	外在原因：	
		CPU竞争	网络问题
		内存交换	
			Redis所有数据保存在内存中，若操作系统将Redis部分内存换出到硬盘，由于内存与银盘读写速度差几个级别，Redis性能急剧下降
			
		排查：
			查询Redis进程号：执行redis-cli -p 6383 info server | grep process_id 
			根据内存号查询内存交换信息：执行cat /proc/process_id/smps |grep Swap
		
		解决：
			保证机器充足可用内存
			确保所有Redis实例设置最大可用内存
			降低系统使用swap优先级

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
内存
	Redis所有数据都保存在内存中，需要高效利用Redis内存，用更少的内存存储更多的数据
	内存消耗：
		内存使用统计：
			命令：info memory	获取内存相关指标
					属性				属性说明
				指标：	used_memory			Redis分配的内存总量
					used_mempry_human		以可读的形式返回used_memeory
					used_memory_rss			操作系统的角度显示Redis进程占用的物理内存总量
					used_memory_peak		内存使用的最大值
					used_memory_peak_human		以可读的形式返回used_memory_peak
					used_memory_lua			Lua引擎消耗的内存大小
					mem_fragmentation_ratio		used_memory_rss/used_memory比值，表示内存碎片率
						>1		碎片率严重，多出的部分内存没有用于数据存储
						<1		硬盘速度远远慢于内存，Redis性能变差，甚至僵死
					mem_allocator			Redis所使用的内存分配器

		Redis进程内消耗：
			进程内消耗 = used_memory{自身内存 + 对象内存 + 缓冲内存} + used_memory_rss-used_memory{内存碎片}
				used_memory_rss	3MB	Redis占用物理内存总量
				used_memory	800KB	Redis内存总量
				
			对象内存(数据) : sizeof(keys) + sizeof(values)

				存储用户所有的数据(key-value数据类型),键对象：字符串，值对象：字符串，哈希，列表，集合，有序集合
					其它数据类型在5种数据结构上实现，value对象根据使用规模不同，占用内存不同	

			缓冲内存：客户端缓冲区 + 复制积压缓冲区 + AOF缓冲区

				客户端缓冲区：客户端缓冲存储客户端连接的输入输出缓冲，输入缓冲最大空间1GB
				复制积压缓冲区：用于实现部分复制功能
				AOF缓冲区：用于在Redis重写期间保存最近的写入命令，消耗内存取决于AOF重写时间和写入命令量	

			内存碎片：Redis再分配，回收物理内存过程中产生。内存分配器jemalloc将内存空间划分为小/大/巨大三范围
					如保存5kb对象时可能会采用8kb块存储，剩下的3kb空间变为内存碎片不能再分配存储，jemalloc针对碎片化问题做了优化
				
		子进程消耗：
			执行AOF/RDB重写时Redis创建的子进程内存消耗
			Linux具有写时复制技术(copy-on-write)Redis执行fork操作产生的子进程内存占用量与父进程相同

	内存管理：
		1 设置内存上限：Redis使用maxmemory参数限制最大可用内存(默认值0)
		
			限制内存目的：
				用于缓存场景，超出内存上线maxmemory时使用LRU等删除策略释放空间
				防止所用内存超过服务器物理内存。因为Redis默认情况下尽可能多使用服务器内存，可能出现服务器内存不足，Redis进程被杀死
			
			注意：maxmemeory限制Redis中used_memory实际使用内存量
			     由于内存碎片率存在，实际消耗内存比maxmemory设置的更大

		1.1 动态调整内存上限：
		 	命令：	config set maxmemory		动态修改最大可用内存
			建议：防止极端情况下系统内存耗尽，所有Redis进程都要配置maxmemory	
			     在保证物理内存可用的情况下，系统中所有Redis实例可以调整maxmemory达到自由伸缩内存的目的
				
		2.内存回收策略：
			2.1 删除过期键对象：
				过期间内存回收机制/内存淘汰机制：
					惰性删除：
						客户端读取带有超时属性的键时，如果已经超过键设置的过期时间，执行删除操作并返回空，存在内存泄露问题
					定时任务删除：
						Redis内部维护一个定时任务，每秒执行10次。定时任务删除过期键采用自适应算法，根据键的过期比例，
						使用快慢两种速率模式回收键
			
			2.2 内存达到maxmemory上限时触发内存溢出控制策略，强制删除选择出来的键值对象：
				Redis支持6种策略/缓存淘汰算法：
					noeviction(默认)		禁止淘汰，内存空间不足以容纳新的键值对，Redis会拒绝写入操作
					Random	随机淘汰
						allkeys-random	随机算出所有键，直到腾出足够空间为之
						volatile-random	随机删除过期键，直到腾出足够空间为之
					volatile-ttl  生存时间	通过设置键值对的过期时间，到达过期时间，Redis自动删除该键值对
					allkeys-lru		根据LRU算法，不管数据有没有设置超时属性，直到腾出足够空间为止
					volatile-lru		根据LRU算法删除设置了超时属性的键，直到腾出足够的空间
				
				命令：config set maxmemory-policy {policy}	设置内存溢出策略

				使用场景和建议：		
					需要收缩Redis内存的场景，可以调小maxmemory实现快速回收(缓存场景)

	优化内存使用：
		1.数据结构选择：根据实际需求选择合适的数据结构存储数据。不同的数据结构在内存占用和性能上有区别
			Redis存储的所有值对象在内部定义为redisObject结构体/存储的数据都使用redisObject封装

			      redisObject

				type:4			对象类型
			      encoding:4		内部编码类型
			   lru:REDIS_LRU_BITS		LRU计时时钟	记录对象最后一次被访问的时间
			      int refcount;		引用计数器	记录当前对象被引用的次数	
			      void *ptr			数据指针		与对象的数据内容相关
					redisObject内部结构
		建议：高并发写入场景，条件允许，字符串长度控制在39个字节以内，减少创建redisObject内存分配次数，提高性能

		2.压缩数据：对于存储的数据进行压缩处理，减少数据在内存的存储空间
			缩减键和值的长度：
				键：设计键，键值越短越好
				值：在业务上精简业务对象，去掉不必要的属性，选择更高效的序列化工具降低字节数组大小

		3.合理设置过期时间/定期清理过期数据：
			对于不需要永久存储的数据，设置合理的过期时间/定期清理过期数据，释放已经失效的键值对
		
		4.共享对象池：	
			指Redis内部维护[0-9999]的整数对象池，实际开发在满足需求的前提下，尽量使用整数对象节省内存	
			
		5.监控内存使用情况：
			定期监控Redis实例的内存使用情况，及时发现内存异常并进行处理
		
		6.启用RDB和AOF持久化：
			通过启用Redis的RDB(快照)和AOF(追加写入文件)持久化机制，可在Redis重启时恢复数据，避免数据丢失
		
		7.限制数据量/控制键数量：
			根据实际需求和硬件资源，合理控制单个Redis实例中存储的数据量，避免数据过多导致内存占用高

		8.分片和集群：
			通过将数据分片存储在多个Redis实例或者使用Redis集群，可以将数据分散存储，降低单个节点内存压力
		
		9.字符串优化：
			字符串结构：Redis实现字符串结构，内部简单动态字符串(SDS)
				
				    SDS
				  int len		已用字节长度
				  int free		未用字节长度
			         char buf[]		字节数组
					字符串结构体SDS

			特点：
				SDS内部实现空间预分配机制，避免频繁修改操作，降低预分配带来的内存浪费和内存碎片化
				惰性删除机制，字符串缩减后的空间不释放，作为预分配空间保留

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Redis集群：				   使用场景			故障转移机制			主要目的				可伸缩性(数据不够随时加)
	主从复制				数据备份和读写分离			手动或哨兵自动转换			数据备份和读写分离			有限
	哨兵模式				关键应用的高可用性			自动故障转移			高可用性和故障自动分离		高可用
	Redis Cluster模式		适用大规模应用高性能需求		自动处理节点故障			高并发和数据分散处理		高可用
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
复制		将多个副本部署到其他机器，满足故障恢复和负载均衡等需求，实现相同数据的多个Redis副本，哨兵和集群都是在复制基础上实现高可用
			
配置：		
	建立复制：
		复制的数据流都是单向的，将一台Redis服务器中的数据复制到其它Redis服务器。前者是主节点(master)，后者是从节点(slave)。	
			
						从节点1
			主节点	----复制--->	从节点2		一对多
						从节点3
						...
		
		配置复制：
			配置文件加入slaveof {masterHost} {masterPort}随Redis启动生效
			redis-server启动命令后加入--slaveof {masterHost} {masterPort}生效
			直接使用命令：slaveof {masterHost} {masterPort}生效
			
		        启动复制：启动两个端口为6379和6380的Redis节点
			在从节点执行：127.0.0.1:6380>slaveof 127.0.0.1 6379		复制过程已开启
				6379作为主节点，6380作为从节点
				
				127.0.0.1:6379 > set hello  redis
				127.0.0.1:6379  > get hello		redis
				127.0.0.1:6380 >  get hello		redis
			
			
			复制相关命令：
				info replication			复制成功后查看复制状态信息
					状态信息：
						role					当前Redis服务器的角色		
						connected_slaves			当前Redis服务器连接的从服务器数量
						master_replid				主服务器运行的ID(replication ID)
						master_replid2				主服务器运行的ID(辅助)
						master_repl_offset			主服务器复制偏移量
						seconf_repl_offset			辅助服务器复制偏移量
						repl_backlog_active			是否激活复制积压区
						repl_backlog_size			复制积压区的大小
						repl_backlog_first_byte_offset		复制积压区的第一个字节的偏移量
				slaveof masterHost masterPort		建立复制		
				slaveof no one				断开复制，从节点晋升主节点。不抛弃原有数据，无法再获取主节点上的数据
				slaveof newMasterIp newMasterPort	将当前从节点对主节点的复制切换到另一个主节点，清空之前所有的数据
		
	安全性：数据比较重要的节点，主节点会设置requirepass参数进行密码验证，所有的客户端访问必须使用auth命令校验
		节点与主节点的复制连接通过一个特殊的客户端完成，需要配置从节点的masterauth参数与主节点密码一致，才能正确连接主节点发起复制
				
	只读:从节点使用slave-read-only=yes配置为只读模式，复制只能从主节点到从节点，从节点的任何修改，主节点无法感知，
		修改从节点造成主从数据不一致，所以线上不要修改从节点的只读模式

	传输延迟：
		主从节点一般部署再不同机器上，复制网络延迟需要考虑
		repl-disable-tcp-nodely参数控制是否关闭TCP_NODELAY(默认关闭)

Redis复制拓扑结构：
	一主一从结构	
		应用：主节点出现宕机时从节点提供故障转移支持
		     当应用(Redis库实现的软件应用程序)写命令且并发量较高且需要持久化时，可以只在从节点上开启AOF，避免持久化对主节点的性能干扰

					redis-A
			                                         ↓                             
					redis-B		
				       一主一从结构

	一主多从结构(主从复制常用)		
		应用：应用(Redis库实现的软件应用程序)利用多个从节点实现读写分离，写命令在主节点上执行，读命令在从节点上执行
		     对于写并发量较高的场景，多从节点会导致主节点过度消耗网络宽带，加重主节点的负载影响服务稳定性

					redis-A
			   ↓                                  ↓                                  ↓
			reids-B		redis-C		redis-D
				       一主多从结构

	树状主从结构	
		应用：从节点不但可以复制主节点数据(数据备份)，同时可以作为其它节点的主节点继续向下层复制
			引入中间层，有效降低主节点负载和需要传送给节点的数据量的压力
			
					redis-A
			   ↓                                                                       ↓
			reids-B				redis-C
                   ↓               ↓
		redis-D		redis-E
				       树状多从结构
					

	Redis主从复制目的：
		1.主节点的数据备份，出现故障，从节点变成主节点，保证数据不丢失
		2.读写分离，主节点执行写命令，从节点执行读耗时命令
	
	复制过程：
		1.保存主节点信息返回
		2.主从节点建立socket连接	丛节点salve内部维护复制相关逻辑，定时任务发现存在新的主节点，尝试与节点建立网络连接
		3.发送ping命令		建立成功后从节点发送ping请求进行首次通信
		4.权限校验		如果主节点设置requirepass参数，需要密码验证，从节点必须配置masterauth参数保证与主节点相同的密码才能通过验证，验证失败，重新发起复制流程
		5.同步数据集		主从复制正常连接后，主节点会把所有的数据发送给从节点
			同步过程：
				全量复制：主节点全部数据一次性发送给从节点，用于初次复制场景
					缺点：数据量较大时，会对主从节点和网络造成很大开销
				部分复制：处理在主从复制中网络闪断等原因造成的数据丢失，从节点再次连接主节点，条件允许，主节点补发丢失数据给从节点
		6.命令持续复制		主节点把当前的数据同步给从节点后，主节点会持续把写命令同步给从节点

、	命令：
		sync/psync runId offset	完成部分复制和全量复制
			runId			从节点所复制主节点的运行Id
			offset			当前从节点已复制的数据偏移量

	心跳机制：
		主从节点建立复制后，之间维护长时间并彼此发送心跳命令
		1.主从节点彼此都有心跳检测机制，模拟成对方客户端进行通信，通过client list命令查看复制相关客户端信息
			主节点连接状态是flags=M,从节点连接状态是flags=S
		2.主节点默认每隔10秒对从节点发送ping命令，判断从节点的存活性和连接状态，参数repl-ping-slave-period控制发送频率
		3.从节点在主线程中每隔1秒发送replconf ack offset命令，给主节点上报当前当前的复制偏移量，体现在info replication体现在lag中
			如果超过repl-timeout值，判定从节点下线并断开复制客户端连接

	异步复制(slaveof命令)：
		主节点不但负责数据读写，还将写命令同步给从节点。写命令的发送过程是异步完成，主节点自身处理完命令后直接返回给客户端，不等待从节点复制完成
	
		主节点复制流程：
			1.主节点6379接收处理命令
			2.命令处理完返回响应结果
			3.对于修改命令异步发送给6380从节点，从节点在主线程中执行复制过程
			
			注意：主从复制过程是异步的，会造成从节点数据相对主节点存在延迟，info repliaction查看延迟字节
	
	手动故障转移：
		指定从节点发起转移流程，主节点角色进行切换，从节点变成新的主节点对外提供服务，旧的主节点变为它从节点
		
		流程：
			1.检测主节点故障
			2.选举新主节点
			3.同步数据，新主节点同步数据给其他从节点，确保数据一致
			4.更新客户端连接信息，客户端重定向到新的主节点
		
	复制应用场景和问题：
		读写分离	对于读占比高的场景，将部分读流量分摊到从节点减轻主节点压力，只对主节点执行写操作
		问题：
			数据延迟		延迟由于异步特性无法避免，业务场景需要允许短时间内的数据延迟，无法容忍大量延迟，编写外部监控程序监听主从节点的复制偏移量
			读过期数据	主节点存储大量超时数据，Redis内部需要维护过期数据删除
				惰性删除:主节点处理读取命令，会检查键是否超时，超时执行del命令删除键，异步发送给从节点/从节点自身不会主动删除超时数据
				定时删除：Redis主节点内部定时任务循环采样一定数量的键，采样的键过期，执行del命令，之后同步给从节点
			从节点故障

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
哨兵模式(Redis Sentinel)：			高可用性和自动故障转移
	目的：解决redis主从复制模式，主节点故障不能提供服务，需要人工将从节点晋升主节点，同时通知应用方更新主节点地址的故障处理方式
					
	名词解释：
		    名词			  	 逻辑结构				    物理结构
		主节点(master)			Redis主服务			一个独立的Redis进程
		从节点(slave)			Redis从服务			一个独立的Redis进程
		Redis数据节点			Redis主服务和从服务		主节点和从节点的进程	
		Sentinel节点			监控Redis数据节点			一个独立的Sentinel进程0
		Sentinel节点集合			若干Sentinel节点的抽象组合		若干Sentinel节点进程
		Redis Sentinel			Redis高可用实现方案		Sentinel节点集合和Redis数据节点进程
		应用方				泛指一个或多个客户端		一个或者多个客户端进程或者线程
	
	主从复制故障处理产生问题：
		主节点出现故障，需要手动将从节点晋升为主节点，同时需要修改应用放主节点地址，需要命令其它节点复制新的主节点，受到人工限制		
		主节点的写能力受到单机的限制
		主节点的存储能力收到单机的限制

	高可用Redis Sentinel方案：
		Redis Sentinel是分布式架构，Redis Sentinel自动完成故障发现和故障转移，并通知应用方
		Redis Sentinel包含若干个Sentinel节点和Redis数据节点

		Sentinel高可用性：对数据节点和其它Sentinel节点进行监控，发现节点不可达，对节点做下线标识
				标识的是主节点，与其他Sentinel节点进行"协商"，当大多数Sentinel节点都认为主节点不可达，
					选举出一个Sentinel节点完成自动故障转移，同时将变化实时通知给Redis应用方，全过程自动

			补充：Sentinel节点本质上是一个特殊的Redis节点，info Sentinel查看Sentinel节点相关信息
				
				 Redis				sentinel-1 sentinel-2 ... sentinel-N

			 复制		  复制					master(监控)

			slave-1		slave-2			slave-1(监控复制)		slave-2(监控复制)
			    Redis主从复制模式				Redis Sentinel架构/拓扑结构

	Redis Sentinel功能：
		监控：Sentinel节点定期检测Redis数据节点，其余Sentinel节点是否可达
		通知：Sentinel节点会将故障转移的结果通知给应用方
		主节点故障转移：实现从节点晋升为主节点并维护后续正确的主从关系
		配置提供者:在Redis Sentinel结构中，客户端在初始化的时候连接的是Sentinel节点集合，获取主节点信息
		
	部署Redis Sentinel：				
		部署拓扑结构：
				   ip			port		别名
		master		127.0.0.1		6379		主节点
		slave1		127.0.0.1		6380		从节点1
		slave2		127.0.0.1		6381		从节点2
		sentinel1	127.0.0.1		26379		sentinel-1节点
		sentinel2	127.0.0.1		26380		sentinel-2节点
		sentinel3	127.0.0.1		26381		sentinel-3节点
			
		部署Redis数据节点：
			reids-server redis-6379.conf				启动主节点
			redis-server redis-6380.conf				启动从节点
			redis-server redis-6381.conf				启动从节点
			redis-cli -h 127.0.0.1 -p 6379 info replication		查看主从关系
			redis-sentinel redis-sentinel-26379.conf		启动Sentinel节点
			redis-server redis-sentinel-26379.conf --sentinel	启动Sentinel节点	

		部署建议：
			生产环境中Redis Sentinel的所有节点应该分布在不同物理机上
			部署至少三个且奇数个的Sentienl节点
			Sentinel节点集合可以只监控一个主节点，也可以监控多个主节点			
			Redis Sentinel中的数据节点和普通Redis数据节点在配置上没有任何区别，添加一些Sentinel节点进行监控		
					
		
			sentinel-1	sentinel-2	...	sentinel-N
		
				   监控			     监控
		
				  master1		   master2
			  复制		    复制	      复制	    复制
			
			slave-1		  slave-2  slave-3	  slave-4
				     Reids Sentinel监控多个主节点

	Sentinel API：		Sentinel节点是一个特殊的Redis节点，有自己专属的API
		sentinel masters				展示所有被监控的主节点状态以及相关统计信息
		sentinel master mastername			展示指定mastername的主节点状态以及相关的统计信息
		sentinel slaves slavename			展示指定slavename的从节点状态以及相关的统计信息
		sentinel sentinels sentinelname			展示指定sentinelname的Sentinel节点集合
		sentinel get-master-addr-by-name mastername	展示指定mastername主节点的IP地址和端口
		sentinel reset pattern				当前Sentinel节点对符合pattern通配符风格主节点的配置进行重置
		sentinel failover mastername			对指定mastername主节点进行强制故障转移，将从节点晋升为主节点
		sentinel ckquorum mastername			检测当前可达的Sentinel节点总数是否达到quorum数
		sentinel flushconfig				将Sentinel节点的配置强制刷到磁盘上
		sentinel remove mastername			取消当前Sentinel节点对于指定mastername主节点的监控
		sentinel monitor mastername ip port quorum	命令完成Sentinel节点对主节点的监控
		sentinel set mastername				动态修改Sentinel节点配置选项
		sentinel is-master-down-by-addr			交换主节点是否下线的判断，根据参数不同，作为Sentinel领导这选举通信方式
		
	Redis Sentinel客户端：
		Jedis作为Redis的Java客户端，Jedis能很好支持Redis Sentinel，使用Jedis连接Jedis Sentinel
		Jedis针对Redis Sentinel给出JedisSentinelPool，JedisSentinelPool连接池保存的连接是针对主节点的
		
		Java操作Redis Sentinel：
			JedisSentinelPool构造方法：
				public JedisSentinelPool(String masterName,Set<String> sentinels,
					final GenericObjectPoolConfig poolConfig,final int connectionTimeout,
					final int soTimeout,
					final String password,final int database,
					final String clientName)

		Redis Sentinel实现原理：
			Redis Sentinel定时任务：
			主观线下和客观线下
			Sentinel领导者选举
			故障转移
			
		Redis Sentinel定时任务：	
			目的：判断节点可不可达到
				
			流程：	1.每隔10秒，每个Sentinel节点会向主节点和从节点发送info命令获取最新拓扑结构
					作用：通过向主节点执行info replication命令，获取从节点的信息
					         当有新的从节点加入立刻感知
					         节点不可达或故障转移后，通过info命令更新节点拓扑信息
			
				2.每隔2秒，每个Sentinel节点向Redis数据节点的_sentinel_:hello频道上发送该Sentinel节点对于主节点的判断以及
				  当前Sentinel节点的信息，同时每个Sentinel节点也订阅该频道，来了解其它Sentinel节点以及它们对于主节点的判断
					作用：发现新的Sentinel节点，订阅频道了解其它Sentinel节点信息，新加入的Sentinel节点，Sentinel节点信息保存并与该Sentinel节点创建连接
					     Sentinel节点之间交换主节点的状态，作为后面客观下线以及领导者选举的依据

				3.每隔1秒，每个Sentinel节点会向主节点，从节点，其余Sentinel节点发送一条ping命令做一次心跳检测，判断节点是否可达

		节点下线/主观下线和客观下线：
			主观下线:每个Sentinel节点对其它节点发送ping命令做心跳检测定时任务，节点超过down-after-milliseconds没有进行有效回复，
					Sentinel节点会对该节点做失败判定(单个节点做下线判定)
			客观下线:Sentienl主观下线的节点是主节点时，该节点通过sentinel is-master-down-by-addr命令向其它Sentinel节点询问对主节点的判断，
					当该主节点下线被多数Sentinel节点做同意判定，这个节点是客观的(多个节点做下线判定)

			命令:sentinel is-master-down-by-addr ip port current_epoch runid
				ip			主节点IP
				port			主节点端口
				current_epoch		当前配置纪元
				runid					
					*				Sentinel节点直接交换对主节点下线的判定		
					当前Sentinel节点的runid		当前节点希望目标节点同意自己成为领导者请求

		Sentinel领导者节点选举/故障恢复(Redis算法实现领导者选举)：
			领导者选举思路：
				1.每个在线的Sentinel节点都有资格成为领导者，当确认主节点主观下线，会向其它Sentinel节点发送sentinel 
				2.收到命令的Sentinel节点，没有同意其它Sentinel节点的命令，同意该节点，否则拒绝
				3.Sentinel节点发现自己的票数已经大于等于max，它将成为领导者
				4.如果此过程没有选举出领导者，将进入下一次选举
				5.替换主节点
				
				注意:一般谁先完成客观下线，谁就是领导者

		故障转移：
		    概念：
			故障转移(failover)指当前主节点(master)发生故障或不可用时，Redis集群会自动将一个从节点晋升为新的主节点，通过自动故障转移保证集群正常对外提供服务
			
		    流程：
			1.在从节点列表中选出一个节点作为新主节点
			2.Sentinel领导者节点对选出来的从节点执行slaveof no one命令成为主节点
			3.Sentinel领导者会向剩余的从节点发送命令，让它们成为新主节点的从节点
			4.Sentinel节点集合将原来的主节点更新为从节点，并保持对原主节点关注，当其回复后命令它复制新的主节点
		
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
集群(Redis Cluster)		Redis Cluster -> 大规模应用集群方案
			
	Redis Cluster：		
		目的：Redis分布式解决方案，在多个节点之间分配数据，实现负载均衡，提高可用性和横向扩展
		功能：
			1.将数据自动分片到多个节点上，每个分片有一个主节点和多个从节点，主节点负责处理写操作，从节点负责复制处理读请求
			2.Redis Cluster自动检测节点故障，当一个节点不可达时，将该节点标记为不可用，从可用的从节点中提升一个主节点
		
	Redis-cluster相关集群命令：
		cluster info					打印集群信息
		cluster nodes					列出集群当前已知所有节点，以及这些节点的相关信息
		cluster meet ip port				将ip和port指定的节点添加到集群中
		cluster forget nodeId				从集群中移除nodeId指定的节点
		cluster replicate masternodeId			将当前从节点设置为指定nodeId主节点的从节点
		cluster saveconfig				将节点的配置文件保存到硬盘里面
		cluster addslots slot [slot ...]		将一个或多个槽指派给当前节点
		cluster delslots slot [slot ...]		移除一个或多个槽对当前节点的指派
		cluster flushslots				移除指派给当前节点的所有槽	
		cluster setslot slot ndoe nodeId		将槽slot指派给nodeId指定的节点
		cluster setslot slot migrating nodeId		将本节点的槽slot迁移到nodeId指定的节点中
		cluster setslot slot importing nodeId		从nodeId指定的节点中导入槽slot到本节点中
		cluster keyslot key				计算键key应该被放在在哪个槽上
		cluster countkeysinslot slot			返回槽slot目前包含的键值对数量
		cluster getkeysinslot slot count		返回count个slot槽中的键
		redis-trib.rb add-node 127.0.0.1:6385 127.0.0.1:6379	集群中实现新节点加入
			
	数据分布：		
		基本概念：
			分区：Redis Cluster将全量数据划分到多个节点上，每个节点负责整体数据的一部分
			分片(Sharding)：Redis Cluster将数据划分为多个逻辑分片(槽/slot)的过程，每个槽包含一个或多个键值对，这些槽被分配到不同节点上
				一节点管理一部分槽，负责和处理槽中的数据
			分槽：Redis Cluster用于划分数据的最小单位，数据项根据key经过哈希算法计算映射到特定的槽
						
					       	       全量数据
														
													分区：数据根据哈希算法划分到多个节点
				节点1			节点2			节点3	
	
													分片：将节点数据划分到槽
			槽1	 槽2	 ..	槽1	槽2	..	槽1	槽2	..
			
													分槽：Redis Cluster中划分数据的最小单位
		数据1	数据2	数据3	数据4	5	6	7	8	9	10	11
			
			注意：Redis集群由多个节点组成，节点数量至少为6个才能保证组成完整高可用的集群	
						
	
		常用分区规则：
			1.顺序分区：关系型数据库设计
				例：比如1~100数字，保存在3个节点上，平均分配到三个节点上

						1~100

					1~33	34~66	67~100
				       	       顺序分区
			
			2.哈希分区：
				节点取余分区/普通哈希原理：
					节点取余：hash(key) % nodes
					对key计算出一个hash值，用哈希值对master数量进行取模，根据余数将key负载到不同节点上

					缺点：
						数据节点伸缩时，节点映射关系需要重新计算，导致数据迁移
						迁移数量和添加节点数据有关，建议翻倍扩容
						
				一致性哈希分区原理：
					为系统中每个节点分配一个token，范围在0~2^32。为每一个数据节点分配一个token值，该节点负责保存此范围内的数据
				
				虚拟槽分区(Redis Cluster使用)		虚拟槽 ---> 哈希槽 ---> CRC(key)
					所有的键根据哈希函数映射到0~16383整数槽内，计算公式：slot = CRC16(key)%16383，每一个节点负责维护一部分槽以及槽所映射的键值数据
					
								数据		     槽				节点
								data		slot-0(0-3276)			node-1
							
						keys		data		slot-1(3277-6553)		node-2
					
					CRC16(key)%16383 ----->	data		slot-2(6554-9830)		node-3
					
								data		slot-3(9831-13107)		node-4

								data		slot-4(13108-16383)		node-5

					Redis虚拟槽分区特点：
						解耦数据和节点之间的关系，简化了节点扩容和收缩难度
						节点自身维护槽的映射关系，不需要客户端或者代理服务维护槽分区元数据
						支持节点，槽，键之间的映射查询，用于数据路由，在线伸缩等场景
	
		集群功能限制：
			key批量操作支持有限	目前只支持具有相同slot值的key执行批量操作
			key事务操作支持有限	多个key分布在不同节点上无法使用事务功能
			复制结构只支持一层		从节点只能复制主节点，不支持嵌套树状复制结构
			不支持多数据库空间		单机下Redis可支持16个数据库，集群模式下只能使用一个数据库，db0
			key作为数据分区的最小粒度，不能将大的键值对象映射到不同节点

	搭建Redis集群：		Redis集群由多个节点组成，节点数量至少为6个才能保证组成完整高可用的集群
		启动节点			
		节点握手
		分配槽
		主从复制

		启动节点(主节点)：
			集群相关配置：
				port 6379				节点端口
				cluster-enabled yes			开启集群模式
				cluster-node-timeout 15000		节点超时时间，单位毫米
				cluster-config-file "nodes-6379.conf"	集群内部配置文件
			
			启动流程：启动 -> 开启集群模式 -> 集群模式启动 -> 存在集群配置文件 -> 使用集群配置文件启动
				
		节点握手	cluster meet ip port		让客户端节点与port节点进行握手通信
			定义：指一批运行在集群模式下的节点通过Gossip协议彼此通信，达到感知对方的过程	
		
			1.节点6379本地创建6380信息对象，并发送meet信息
			2.节点6380接受道meet信息后，保存6379节点信息并回复pong消息
			3.节点6379/6380彼此定期通过ping/pong消息进行正常的节点通信
		
		分配槽(主节点)：			
			节点建立握手之后集群不能正常工作，集群处于下线状态，所有数据读写被禁止，槽分配到节点后，集群进入在线状态
			Redis集群把所有的数据映射到16384个槽中。每个key会映射一个固定的槽，只有节点分配了槽，才能响应这些槽关联的键命令
						
			命令：	cluster addslots {0...5461}		为当前节点分配槽
						
		主从复制:
			一个完整的集群，负责处理槽的节点应该具有从节点，保证出现故障时自动进行故障转移
					
			命令：	cluster replicate nodeId		将一个节点成为从节点

	用redis-trib.rb搭建集群：
		redis-trib.rb采用Ruby实现的Redis集群管理工具。
			注意：使用之前需要安装Ruby依赖环境
		
	节点通信：
		分布式存储需要提供维护节点元数据信息的机制：集中式和P2P方式
		元数据：节点负责哪些数据，是否出现故障等状态信息
		
		Gossip协议(流言/流行病协议)  <----	 Redis节点通信实现方式
		原理：当Redis Cluster中的某个节点有信息更新或状态变化时，该节点通过gossip协议将信息广播给其他节点
			其他节点收到消息，更新自己的节点信息并响应做出调整，确保集群的一致性和可用性
		原理(简略)：节点彼此不断通信交换数据，确保集群中各个节点之间的信息同步和一致性

		通信过程：
			1.集群每个节点会开开辟一个TCP通道(集群总线Cluster bus)，用于节点之间彼此通信		通信端口：基础端口 + 10000
			2.每个节点在固定周期内通过特定规则选择几个节点发送ping消息
				补充：
					节点定时任务
					     ↓
				     每秒执行10次，间隔1s
					     ↓
					     ↓
					选择发送节点		
					每秒随机5次		ping消息数据
				     找出最久没通信节点		节点自身信息
							→→   1/10其他节点信息	→→    发送ping消息
					最后通信时间
				      大于node-time/2
							选择通信节点规则和消息携带数据量		
			3.接收到ping消息的节点用pong消息作为响应
		
			通过不断的ping/pong消息通信，经过一段时间所有节点都会知道集群全部节点的最新状态，从而达到状态同步
		
		Gossip消息  --->  节点彼此发送的是Gossip消息
			常用Gossip消息：	
				ping消息：用于检测节点是否在线和交换彼此状态信息。ping消息封装自身节点和部分其他节点的状态数据				
				pong消息：节点可以向集群内广播自身pong消息通知整个集群对自身状态进行
					 更新响应信息回复给发送方确认消息正常通信，封装自身状态数据
						6379	ping消息      6380  →	
						6379	pong消息	     6380  ←	
				
					  		pong消息	      6380 →
						6379	pong消息	      6381 →
							pong消息	      6382 →						

				meet消息：通知新节点加入。消息发送者通知接收者加入到当前集群
						6379	meet消息      6380  →	
						6379	pong消息	     6380  ←	

				fail消息：节点判定集群内另一个节点下线，向集群内广播fail消息，其他节点接收到fail消息将对应节点更新为下线状态
							fail消息	      6380 →
						6379	fail消息	      6381 →
							fail消息	      6382 →

			消息格式：消息头和消息体
				消息头：包含发送节点自身状态数据
					结构：clusterMsg
				消息体：包含Gossip消息
					结构：clutserMsgData
			接收点收到ping/meet消息，解析消息头和消息体
				解析消息头：消息头包含发送节点信息，发送节点是新节点，消息是meet类型，加入到本地节点列表
					   如果是已知节点，尝试更新发送节点的状态
				解析消息体：如果是新节点，尝试发起与新节点的meet握手流程
					    如果是已知节点，根据flags字段判断该节点是否下线，用于故障转移
	
	集群伸缩(Redis提供节点扩容和收缩方案):
		集群伸缩 = 槽和数据在节点之间的移动
		
		节点扩容：为集群添加节点扩容，通过相关命令将一部分槽和数据迁移给新节点
		节点收缩：下线部分节点

		扩容集群：
			1.准备新节点	准备好新节点运行在集群模式，启动新节点
			2.加入集群	新节点cluster meet加入到现有集群
			3.迁移槽和数据	
				槽迁移计划：确定原有节点哪些槽需要迁移到新节点，确保各节点负责相似数量的槽，将槽内数据从源节点迁移到目标节点	
				迁移数据：数据迁移是逐个槽进行	
					命令：
						cluster setslot slot importing sourceNodeId		目标节点导入槽数据
						cluster setslot slot migrating targetNodeId		源节点迁出槽数据
				
		缩减集群：
			流程：
				1.确定下线节点是否有负责的槽，如果是，将槽迁移到其他节点
				2.当下线节点不负责槽或本身是从节点时，通知集群内其他节点忘记下线节点，所有节点忘记该节点正常关闭
			
			1.下线迁移槽	下线节点将自己负责的槽迁移到其他节点
				命令：
					redis -cli --cluster reshard --cluster-from 迁出节点ID 		将该节点的槽位迁移到其他节点
						--cluster -to 接收槽节点ID --cluster-slots 迁出槽数量 已存在节点ip 端口
					redis-cli --cluster forget <要下线节点的ID>			集群忘记要下线的节点，从集群中移除		

	请求路由：		
		请求重定向:ASK和MOVED错误机制			处理数据分片迁移和故障恢复的重要机制	
			
		MOVED重定向：
			集群模式下，Redis接收任何键相关命令首先计算键对应的槽，再找出对应节点，然后返送指令
				节点是自身，处理键命令；否则回复MOVED重定向错误，通知客户端请求正确的节点

				重定向信息：键所对应的槽以及负责该槽的节点地址
				
					补充：redis-cli -p 6379 -c		支持自动重定向
				
			计算槽：根据键的有效部分使用CRC16函数计算出散列值，再取对16383的余数，得到slot编号
			查找槽节点：查找槽所对应的节点。集群内通过消息交换每个节点都会知道所有节点的槽信息。客户端可以随机连接集群内任意Redis获取键所在节点

			Smart客户端Jedis(Smart客户端支持集群协议)：
				Smart客户端内部维护slot -> node的映射关系，本地可实现键到节点的查找
				MOVED重定向负责协助Smart客户端更新slot -> node映射

				JedisCluster：Redis客户端Jedis提供的一个用于连接和操作Redis集群的工具类
					初始化方法：
						public JedisCluster(Set<HostAndPort> jedisClusterNode,int connectionTimeout,int soTimeout,
							int maxAttempts,final GenericObjectPoolConfig poolConfig){}
					
					方法参数：
						Set<HostAndPort> jedisClusterNode		所有Redis Cluster节点信息
						int connectionTimeout				连接超时
						int soTimeout					读写超时		
						int maxAttempts					重试次数
						GenericObjectPoolConfig poolConfig		连接池参数

				JedisCluster操作集群流程：
					1.计算slot并根据slots缓存获取目标节点连接，发送命令
					2.如果出现连接错误，使用随机连接重新执行键命令，每次命令重试对redis-rections参数-1
					3.捕获到MOVED重定向错误，使用cluster slots命令更新slots缓存
					4.重复执行1-3步，知道命令执行成功，或者当redirecyions<=0时抛出JedisClusterMaxRedirectionException异常
					
		ASK重定向：	
			当一客户端发送一个命令到Redis集群中的某个节点，如果该节点不负责该键的数据，返回ASK错误给客户端。如果存在该键的数据，直接
				执行并返回客户端结果。客户端收到ASK错误时，会根据错误信息重新发送asking命令到正确的节点，实现了数据操作的重定向
			
			补充：asking命令是一次性的
				
			ASK重定向异常：(error) ASK {slot} {targetIP}:{targetPort}

		注意：在使用smart客户端批量操作集群时，需要评估mget/mset，Pipieline等在slot迁移场景下的容错性，防止集群迁移造成大量错误和数据丢失的情况

		ASK重定向和MOVED重定向区别：
			ASK重定向		集群正在进行slot数据迁移，客户端无法知道什么时候完成迁移，临时性重定向，不会更新slots缓存
			MOVED重定向		键对应的槽已经明确指定到新的节点，需要更新slots缓存

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
缓存设计	
	缓存目的：缓存能有效加速应用读写速度，降低后端负载(热点数据：双十一自己买鞋11点准时发售，瞬间会有大量请求过来)

	缓存逻辑：判断内存中缓存数据是否存在，存在读取数据，不存在查询数据库，将数据载入数据(将查到的数据缓存起来)
		数据库中的数据与Redis中的数据必须保持一致性(MySQL中的数据更新，删除Redis中的数据(Redis中没有缓存，重新查询数据库))

		缓存数据的数据结构：Map<key,value>		value对应五种数据结构类型
		
	              客户端	
	穿透	↑↓		↑
	     loomFilter		
	     缓存层redis		↑		缓存数据一般情况下时存储在内存中，可以持久化存储数据到硬盘上
		↑↓		↑
		      存储层mysql
		     缓存架构
	
		熔断：当发现存储层挂掉，可以让客户端的请求直接打在缓存层上，不管有没有获取到数据直接返回			↓↑
		回写：将数据从内存数据库从Redis中异步写入持久化存储介质(硬盘)中
			回写方式：
				RDB持久化:Redis定期生成RDB快照文件进行回写
				AOF持久化:AOF将每次操作追加到日志文件，确保操作都被记录下来

	缓存架构优点：
		加速读写：Redis存储数据(缓存)是存储在内存中，读写速度非常快，加速读写
		降低后端负载：帮助后端减少访问量和复杂计算(复杂SQL语句)

	缓存中间件：
		Memchache:
			支持简单数据类型
			不支持数据持久化存储
			不支持主从
			不支持分片
		Redis(主流缓存中间件):
			数据类型丰富
			支持数据磁盘持久化存储
			支持主从
			支持分片
	
	缓存过期策略：
		定时过期：最简单的过期策略，给每个缓存数据设置过期时间。在过期时间后缓存数据自动删除
		惰性过期：客户端读取带有超时属性的键时，如果已经超过键设置的过期时间，立即删除并返回空(在需要时才检查过期)
		定期过期(主动更新):定期扫描缓存中的键，定期(默认每秒钟)随机抽取一些过期键并进行删除		
		LRU/LFU/FIFO剔除算法(内存淘汰策略)：缓存使用量超过了预设的最大值，采用剔除算法对现有的数据剔除
		自适应过期:一些缓存系统会根据缓存项的访问频率和历史访问模式动态调整缓存项的过期时间(保持热点数据保持在缓存中)
		
		建议：低一致性业务配置最大内存和淘汰策略
		     高一致性业务结合使用定时过期和定期过期，即使主动更新出问题，也能在过期时间后删除脏数据		
		
		     补充:低一致性业务为提高性能而牺牲数据的一致性的设计策略

	Redis缓存使用注意事项/问题：
		缓存穿透：客户端向后端发送请求时，先去缓存层查看，查看是否有相应数据，如果有直接返回。缓存中如果没有，去存储层查询
				若该数据在存储层数据库中也不存在，请求不断穿透缓存一致到达数据库
			
			原因：自身业务代码或数据出现问题/恶意攻击，爬虫造成大量空命中
			后果：后端负载极大
			解决：1 改进业务加强监控警报
			     2(推荐使用)缓存空对象,这个key在redis和mysql上都不存在，仍然将key写入redis，value = "",设置较短的过期时间，自动剔除
			     3.引入布隆过滤器，将存在的key用过滤器提前保存起来，做第一层拦截。查询redis/mysql之前都先判定一下key是否在布隆过滤器上存在，不存在就不查了
			     4.做好数据的基础格式校验
			     5.做好热点参数的限流
					
				两种方案对比：				
					缓存空对象		数据命中不高(穿透)				代码维护简单
								数据频繁变化实时性高			需要过多的缓存空间
													数据不一致
			
					布隆过滤器		数据命中不高(穿透)				代码维护复杂
								数据相对固定实时性低			缓存空间占用少
				
			缓存空对象实现代码：
				String get(String key){
					String cacheValue = cache.get(key);
					if(StringUtils.isBlank(cacheValue)){
						String storageValue = storage.get(key);
						cache.set(key,stroageValue);
						if(storageValue == null){
							cache.expire(key,60 * 5);
						}
						return storageValue;
					}else{
						return cacheValue;
					}
				}
		
		缓存雪崩(stampeding herd)：Redis缓存中大规模的key失效或者Redis宕机，大量请求达到存储层数据库带来巨大压力
			
			解决：
				1 保证缓存层服务高可用(利用Redis Sentienl和Redis Cluster)
				2 提前演练。在项目上线前，演练缓存层宕掉的情况，以及后端的负载情况以及可能出现的问题
				3 给缓存业务添加降级限流策略(SpringCloud知识点)
				4 给不同的key添加随机的ttl存活时间

		缓存击穿(热点key问题)：
			针对被高并发访问并且缓存重建业务较复杂的key失效，导致大量的请求访问到存储层数据库引起数据库宕机	
				高并发访问：多个线程(10000条)线程同时访问
				缓存重建业务复杂：缓存失效瞬间，有大量线程重建缓存，导致后端负载加大	
				
			解决：
				1 互斥锁	尝试获取互斥锁，只允许一个线程重建缓存，其他线程等待重建缓存的线程执行完，重新从缓存获取数据
				2 基于统计的方式发现热点key，设置为永不过期
				3 进行必要的服务降级，关闭一些不重要的功能，只保留核心功能
				4 逻辑过期，给redis缓存字段添加一个过期时间(牺牲数据一致性)
					线程查询数据库时，先判断是否已经过期，如果过期等待互斥锁，其他进程，获取互斥锁失败，返回旧数据

		无底洞(集群)：
			缓存节点很多，增加新的缓存节点。性能不但没有好转反而下降
				
			解决：
				常见IO优化思路：
					优化SQL语句
					减少网络通信次数
						串行IO
						并行IO
						hash_tag实现
					降低接入成本，使用连接池/NIO

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
分布式锁(简略版本)：
	定义：分布式系统中的锁，管理和协调多个节点对共享资源访问控制的机制
	
	分布式锁特性：
		互斥性	分布式锁能够保证同一时刻只有一个节点能够获取到锁，其他节点必须等锁释放才能继续操作
		一致性	分布式锁能够确保对共享资源的访问顺序是有序的，避免数据出现不一致的情况
		容错性	分布式锁需要考虑分布式系统可能存在的异常情况，保证各种情况都能正常运行
		高性能	分布式需要具备高性能，尽量减少对共享资源的锁定
	
	基于Redis的分布式锁：
		setnx lock.key lock.value		
			当可以不存在key时，将key的值设为value，若key已经存在，setnx不做任何动作
			返回1，该进程获得锁，将key设置为value
			返回0，其他进程已经获得锁，进程等待其他进程释放锁

		del lock.key
			锁的线程完成之后，del命令释放锁，其他进程继续执行setnx命令获得锁
			
		expire timeout/setnx lock.key lock.value expireTime	
			线程获取锁之后，在执行任务过程中挂掉，来不及释放锁，产生死锁情况，设置锁超时时间
		
			
		











		